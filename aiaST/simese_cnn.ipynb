{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入一些套件\n",
    "- 基本上是使用keras，部分沒有內建的就用keras提供的backend+lambda處理\n",
    "- Data 用 Mnist 手寫資料集\n",
    "- 下面的 Code 是根據 https://gist.github.com/mmmikael/0a3d4fae965bdbec1f9d 改的\n",
    "- 主要修改的部分，為版本過舊而不支援的問題、loss funtion定義、base_network的定義等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten, MaxPooling2D, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義一些接下來會用到的function\n",
    "- euclidean_distance計算歐式距離\n",
    "- eucl_dist_output_shape，轉換euclidean_distance輸出的tensor shape，輸入lambda層用的\n",
    "- contrastive_loss 剛剛提到的第一種loss\n",
    "- create_pairs把mnist的data分成pairs，並且確保相似的與不相似的pair data的數量是一致的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean((1 - y_true) * K.square(y_pred) + y_true * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n",
    "    for d in range(10):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, 10)\n",
    "            dn = (d + inc) % 10\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "- 同除255做normalize\n",
    "- created pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train_image = X_train\n",
    "X_test_image = X_test\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "input_shape = (28,28,1)\n",
    "nb_epoch = 10\n",
    "num_classes = 1\n",
    "# create training+test positive and negative pairs\n",
    "digit_indices = [np.where(y_train == i)[0] for i in range(10)]\n",
    "tr_pairs, tr_y = create_pairs(X_train, digit_indices)\n",
    "\n",
    "digit_indices = [np.where(y_test == i)[0] for i in range(10)]\n",
    "te_pairs, te_y = create_pairs(X_test, digit_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立siamese_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    model = Sequential()  \n",
    "    model.add(Conv2D(filters=16,  \n",
    "                 kernel_size=(5,5),  \n",
    "                 padding='same',  \n",
    "                 input_shape=input_shape,  \n",
    "                 activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))  \n",
    "    model.add(Conv2D(filters=36,  \n",
    "                 kernel_size=(5,5),  \n",
    "                 padding='same',  \n",
    "                 input_shape=input_shape,  \n",
    "                 activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "    model.add(Dropout(0.25))  \n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(128, activation='relu'))  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network = create_base_network(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_a = Input(shape=(input_shape))\n",
    "input_b = Input(shape=(input_shape))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108400 samples, validate on 17820 samples\n",
      "Epoch 1/10\n",
      "108400/108400 [==============================] - 142s - loss: 0.0621 - val_loss: 0.0272\n",
      "Epoch 2/10\n",
      "108400/108400 [==============================] - 142s - loss: 0.0293 - val_loss: 0.0217\n",
      "Epoch 3/10\n",
      "108400/108400 [==============================] - 143s - loss: 0.0232 - val_loss: 0.0174\n",
      "Epoch 4/10\n",
      "108400/108400 [==============================] - 143s - loss: 0.0204 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "108400/108400 [==============================] - 139s - loss: 0.0186 - val_loss: 0.0159\n",
      "Epoch 6/10\n",
      "108400/108400 [==============================] - 137s - loss: 0.0174 - val_loss: 0.0155\n",
      "Epoch 7/10\n",
      "108400/108400 [==============================] - 137s - loss: 0.0164 - val_loss: 0.0152\n",
      "Epoch 8/10\n",
      "108400/108400 [==============================] - 137s - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 9/10\n",
      "108400/108400 [==============================] - 137s - loss: 0.0150 - val_loss: 0.0142\n",
      "Epoch 10/10\n",
      "108400/108400 [==============================] - 139s - loss: 0.0145 - val_loss: 0.0146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13197cfd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model(inputs=[input_a, input_b], outputs=distance)\n",
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y),\n",
    "          batch_size=128,\n",
    "          epochs=nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/models.py:287: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model.h5', custom_objects={'contrastive_loss': contrastive_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Accuracy on training set: 99.05%\n",
      "* Accuracy on test set: 97.91%\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(predictions, labels):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() > 0.5].mean()\n",
    "\n",
    "# compute final accuracy on training and test sets\n",
    "pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(pred, tr_y)\n",
    "pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(pred, te_y)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show結果用的function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showpre(img_num1,img_num2):\n",
    "    predtest =  model.predict([X_test[img_num1:img_num1+1],X_test[img_num2:img_num2+1]])\n",
    "    print(predtest)\n",
    "    if(predtest<0.5):\n",
    "        print('true')\n",
    "    else:\n",
    "        print('false')\n",
    "    plt.subplot(121),plt.imshow(X_test_image[img_num1], cmap='gray'),plt.title(img_num1)\n",
    "    plt.subplot(122),plt.imshow(X_test_image[img_num2], cmap='gray'),plt.title(img_num2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "15\n",
      "23\n",
      "45\n",
      "52\n",
      "53\n",
      "59\n",
      "102\n",
      "120\n",
      "127\n",
      "129\n",
      "132\n",
      "152\n",
      "153\n",
      "155\n",
      "162\n",
      "165\n",
      "167\n",
      "182\n",
      "187\n",
      "207\n",
      "211\n",
      "218\n",
      "219\n",
      "240\n",
      "253\n",
      "261\n",
      "283\n",
      "289\n",
      "317\n",
      "319\n",
      "333\n",
      "340\n",
      "347\n",
      "351\n",
      "352\n",
      "356\n",
      "364\n",
      "367\n",
      "375\n",
      "395\n",
      "397\n",
      "406\n",
      "412\n",
      "433\n",
      "460\n",
      "469\n",
      "478\n",
      "483\n",
      "491\n",
      "502\n",
      "509\n",
      "518\n",
      "540\n",
      "570\n",
      "588\n",
      "604\n",
      "618\n",
      "638\n",
      "645\n",
      "654\n",
      "674\n",
      "692\n",
      "694\n",
      "710\n",
      "711\n",
      "720\n",
      "739\n",
      "751\n",
      "766\n",
      "778\n",
      "779\n",
      "785\n",
      "791\n",
      "797\n",
      "812\n",
      "856\n",
      "857\n",
      "866\n",
      "869\n",
      "897\n",
      "934\n",
      "935\n",
      "951\n",
      "955\n",
      "970\n",
      "978\n",
      "1003\n",
      "1022\n",
      "1032\n",
      "1041\n",
      "1046\n",
      "1070\n",
      "1073\n",
      "1082\n",
      "1087\n",
      "1089\n",
      "1102\n",
      "1113\n",
      "1115\n",
      "1131\n",
      "1135\n",
      "1144\n",
      "1146\n",
      "1168\n",
      "1169\n",
      "1190\n",
      "1221\n",
      "1233\n",
      "1235\n",
      "1243\n",
      "1252\n",
      "1258\n",
      "1272\n",
      "1281\n",
      "1285\n",
      "1289\n",
      "1299\n",
      "1331\n",
      "1334\n",
      "1339\n",
      "1340\n",
      "1370\n",
      "1376\n",
      "1378\n",
      "1393\n",
      "1405\n",
      "1406\n",
      "1421\n",
      "1447\n",
      "1460\n",
      "1466\n",
      "1467\n",
      "1471\n",
      "1473\n",
      "1476\n",
      "1493\n",
      "1510\n",
      "1521\n",
      "1525\n",
      "1550\n",
      "1598\n",
      "1618\n",
      "1629\n",
      "1635\n",
      "1637\n",
      "1639\n",
      "1641\n",
      "1653\n",
      "1670\n",
      "1672\n",
      "1677\n",
      "1684\n",
      "1693\n",
      "1737\n",
      "1747\n",
      "1752\n",
      "1755\n",
      "1761\n",
      "1810\n",
      "1833\n",
      "1846\n",
      "1847\n",
      "1860\n",
      "1866\n",
      "1874\n",
      "1879\n",
      "1896\n",
      "1902\n",
      "1910\n",
      "1911\n",
      "1917\n",
      "1931\n",
      "1940\n",
      "1948\n",
      "1954\n",
      "1967\n",
      "1970\n",
      "1999\n",
      "2001\n",
      "2003\n",
      "2021\n",
      "2029\n",
      "2030\n",
      "2035\n",
      "2037\n",
      "2040\n",
      "2064\n",
      "2073\n",
      "2077\n",
      "2078\n",
      "2100\n",
      "2103\n",
      "2113\n",
      "2114\n",
      "2125\n",
      "2134\n",
      "2159\n",
      "2162\n",
      "2180\n",
      "2192\n",
      "2207\n",
      "2214\n",
      "2224\n",
      "2237\n",
      "2241\n",
      "2247\n",
      "2279\n",
      "2282\n",
      "2291\n",
      "2322\n",
      "2339\n",
      "2346\n",
      "2369\n",
      "2400\n",
      "2413\n",
      "2445\n",
      "2452\n",
      "2460\n",
      "2476\n",
      "2487\n",
      "2515\n",
      "2518\n",
      "2525\n",
      "2526\n",
      "2540\n",
      "2545\n",
      "2546\n",
      "2554\n",
      "2556\n",
      "2558\n",
      "2559\n",
      "2569\n",
      "2573\n",
      "2574\n",
      "2581\n",
      "2586\n",
      "2597\n",
      "2604\n",
      "2606\n",
      "2611\n",
      "2616\n",
      "2644\n",
      "2653\n",
      "2668\n",
      "2670\n",
      "2682\n",
      "2686\n",
      "2689\n",
      "2697\n",
      "2698\n",
      "2727\n",
      "2743\n",
      "2768\n",
      "2772\n",
      "2773\n",
      "2775\n",
      "2790\n",
      "2797\n",
      "2798\n",
      "2805\n",
      "2810\n",
      "2814\n",
      "2829\n",
      "2832\n",
      "2839\n",
      "2850\n",
      "2855\n",
      "2903\n",
      "2909\n",
      "2913\n",
      "2919\n",
      "2922\n",
      "2925\n",
      "2930\n",
      "2948\n",
      "2951\n",
      "2956\n",
      "2957\n",
      "2969\n",
      "2970\n",
      "2986\n",
      "2987\n",
      "3007\n",
      "3022\n",
      "3028\n",
      "3053\n",
      "3093\n",
      "3095\n",
      "3100\n",
      "3102\n",
      "3113\n",
      "3115\n",
      "3117\n",
      "3119\n",
      "3127\n",
      "3145\n",
      "3157\n",
      "3171\n",
      "3183\n",
      "3199\n",
      "3220\n",
      "3275\n",
      "3295\n",
      "3311\n",
      "3312\n",
      "3321\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3345\n",
      "3372\n",
      "3393\n",
      "3408\n",
      "3414\n",
      "3416\n",
      "3462\n",
      "3468\n",
      "3470\n",
      "3506\n",
      "3537\n",
      "3552\n",
      "3556\n",
      "3558\n",
      "3565\n",
      "3569\n",
      "3570\n",
      "3590\n",
      "3591\n",
      "3595\n",
      "3619\n",
      "3623\n",
      "3631\n",
      "3636\n",
      "3645\n",
      "3654\n",
      "3663\n",
      "3678\n",
      "3691\n",
      "3702\n",
      "3750\n",
      "3754\n",
      "3756\n",
      "3763\n",
      "3776\n",
      "3778\n",
      "3788\n",
      "3797\n",
      "3806\n",
      "3810\n",
      "3814\n",
      "3826\n",
      "3837\n",
      "3855\n",
      "3860\n",
      "3863\n",
      "3877\n",
      "3890\n",
      "3893\n",
      "3898\n",
      "3902\n",
      "3907\n",
      "3917\n",
      "3918\n",
      "3928\n",
      "3929\n",
      "3952\n",
      "3955\n",
      "3957\n",
      "3960\n",
      "3968\n",
      "3994\n",
      "4031\n",
      "4052\n",
      "4054\n",
      "4056\n",
      "4059\n",
      "4067\n",
      "4072\n",
      "4076\n",
      "4094\n",
      "4108\n",
      "4118\n",
      "4131\n",
      "4152\n",
      "4177\n",
      "4196\n",
      "4202\n",
      "4219\n",
      "4226\n",
      "4233\n",
      "4236\n",
      "4254\n",
      "4255\n",
      "4261\n",
      "4263\n",
      "4271\n",
      "4300\n",
      "4302\n",
      "4307\n",
      "4310\n",
      "4312\n",
      "4315\n",
      "4323\n",
      "4330\n",
      "4338\n",
      "4340\n",
      "4355\n",
      "4356\n",
      "4359\n",
      "4360\n",
      "4364\n",
      "4368\n",
      "4374\n",
      "4378\n",
      "4381\n",
      "4420\n",
      "4422\n",
      "4440\n",
      "4461\n",
      "4463\n",
      "4472\n",
      "4520\n",
      "4529\n",
      "4548\n",
      "4569\n",
      "4577\n",
      "4583\n",
      "4596\n",
      "4637\n",
      "4645\n",
      "4689\n",
      "4696\n",
      "4711\n",
      "4712\n",
      "4722\n",
      "4728\n",
      "4749\n",
      "4762\n",
      "4763\n",
      "4766\n",
      "4771\n",
      "4809\n",
      "4810\n",
      "4828\n",
      "4830\n",
      "4844\n",
      "4867\n",
      "4888\n",
      "4892\n",
      "4902\n",
      "4915\n",
      "4933\n",
      "4942\n",
      "4971\n",
      "4979\n",
      "5020\n",
      "5021\n",
      "5056\n",
      "5083\n",
      "5098\n",
      "5102\n",
      "5111\n",
      "5134\n",
      "5152\n",
      "5160\n",
      "5170\n",
      "5174\n",
      "5187\n",
      "5194\n",
      "5196\n",
      "5197\n",
      "5206\n",
      "5207\n",
      "5222\n",
      "5223\n",
      "5229\n",
      "5275\n",
      "5285\n",
      "5295\n",
      "5302\n",
      "5325\n",
      "5339\n",
      "5347\n",
      "5351\n",
      "5364\n",
      "5374\n",
      "5389\n",
      "5397\n",
      "5400\n",
      "5410\n",
      "5420\n",
      "5432\n",
      "5445\n",
      "5451\n",
      "5473\n",
      "5480\n",
      "5488\n",
      "5510\n",
      "5518\n",
      "5528\n",
      "5570\n",
      "5571\n",
      "5572\n",
      "5574\n",
      "5579\n",
      "5598\n",
      "5608\n",
      "5618\n",
      "5624\n",
      "5632\n",
      "5633\n",
      "5658\n",
      "5662\n",
      "5668\n",
      "5682\n",
      "5697\n",
      "5706\n",
      "5711\n",
      "5726\n",
      "5735\n",
      "5742\n",
      "5752\n",
      "5769\n",
      "5779\n",
      "5802\n",
      "5807\n",
      "5821\n",
      "5833\n",
      "5843\n",
      "5852\n",
      "5862\n",
      "5867\n",
      "5874\n",
      "5885\n",
      "5891\n",
      "5910\n",
      "5913\n",
      "5922\n",
      "5937\n",
      "5947\n",
      "5957\n",
      "5964\n",
      "5972\n",
      "5981\n",
      "5982\n",
      "5985\n",
      "5997\n",
      "6028\n",
      "6042\n",
      "6043\n",
      "6053\n",
      "6067\n",
      "6077\n",
      "6087\n",
      "6095\n",
      "6120\n",
      "6136\n",
      "6142\n",
      "6146\n",
      "6148\n",
      "6155\n",
      "6165\n",
      "6186\n",
      "6196\n",
      "6206\n",
      "6215\n",
      "6216\n",
      "6227\n",
      "6236\n",
      "6244\n",
      "6257\n",
      "6270\n",
      "6277\n",
      "6282\n",
      "6291\n",
      "6314\n",
      "6324\n",
      "6333\n",
      "6341\n",
      "6368\n",
      "6385\n",
      "6386\n",
      "6390\n",
      "6392\n",
      "6405\n",
      "6414\n",
      "6415\n",
      "6476\n",
      "6483\n",
      "6486\n",
      "6491\n",
      "6500\n",
      "6518\n",
      "6522\n",
      "6525\n",
      "6530\n",
      "6537\n",
      "6544\n",
      "6548\n",
      "6573\n",
      "6598\n",
      "6600\n",
      "6611\n",
      "6620\n",
      "6638\n",
      "6706\n",
      "6716\n",
      "6728\n",
      "6746\n",
      "6775\n",
      "6788\n",
      "6803\n",
      "6813\n",
      "6823\n",
      "6832\n",
      "6860\n",
      "6866\n",
      "6879\n",
      "6880\n",
      "6884\n",
      "6886\n",
      "6899\n",
      "6908\n",
      "6909\n",
      "6932\n",
      "6942\n",
      "6952\n",
      "6964\n",
      "6965\n",
      "6977\n",
      "6981\n",
      "6991\n",
      "7003\n",
      "7018\n",
      "7029\n",
      "7036\n",
      "7057\n",
      "7067\n",
      "7077\n",
      "7090\n",
      "7108\n",
      "7134\n",
      "7142\n",
      "7155\n",
      "7160\n",
      "7178\n",
      "7187\n",
      "7195\n",
      "7240\n",
      "7241\n",
      "7264\n",
      "7274\n",
      "7284\n",
      "7294\n",
      "7304\n",
      "7306\n",
      "7315\n",
      "7324\n",
      "7351\n",
      "7352\n",
      "7372\n",
      "7388\n",
      "7393\n",
      "7397\n",
      "7403\n",
      "7414\n",
      "7430\n",
      "7437\n",
      "7448\n",
      "7451\n",
      "7454\n",
      "7474\n",
      "7475\n",
      "7478\n",
      "7498\n",
      "7511\n",
      "7521\n",
      "7531\n",
      "7541\n",
      "7542\n",
      "7559\n",
      "7577\n",
      "7578\n",
      "7583\n",
      "7602\n",
      "7612\n",
      "7622\n",
      "7630\n",
      "7643\n",
      "7649\n",
      "7659\n",
      "7672\n",
      "7673\n",
      "7676\n",
      "7679\n",
      "7698\n",
      "7715\n",
      "7732\n",
      "7742\n",
      "7752\n",
      "7777\n",
      "7779\n",
      "7793\n",
      "7797\n",
      "7808\n",
      "7809\n",
      "7819\n",
      "7826\n",
      "7842\n",
      "7850\n",
      "7859\n",
      "7870\n",
      "7888\n",
      "7918\n",
      "7938\n",
      "7948\n",
      "7958\n",
      "7965\n",
      "7974\n",
      "7988\n",
      "7996\n",
      "7997\n",
      "8034\n",
      "8035\n",
      "8038\n",
      "8049\n",
      "8062\n",
      "8072\n",
      "8082\n",
      "8089\n",
      "8122\n",
      "8132\n",
      "8142\n",
      "8149\n",
      "8158\n",
      "8160\n",
      "8170\n",
      "8180\n",
      "8185\n",
      "8192\n",
      "8214\n",
      "8224\n",
      "8232\n",
      "8270\n",
      "8275\n",
      "8299\n",
      "8327\n",
      "8331\n",
      "8348\n",
      "8366\n",
      "8386\n",
      "8412\n",
      "8415\n",
      "8444\n",
      "8445\n",
      "8447\n",
      "8453\n",
      "8463\n",
      "8473\n",
      "8487\n",
      "8502\n",
      "8507\n",
      "8531\n",
      "8539\n",
      "8553\n",
      "8563\n",
      "8571\n",
      "8578\n",
      "8601\n",
      "8630\n",
      "8632\n",
      "8643\n",
      "8645\n",
      "8652\n",
      "8653\n",
      "8656\n",
      "8665\n",
      "8676\n",
      "8686\n",
      "8696\n",
      "8702\n",
      "8710\n",
      "8711\n",
      "8737\n",
      "8741\n",
      "8747\n",
      "8761\n",
      "8774\n",
      "8783\n",
      "8788\n",
      "8803\n",
      "8813\n",
      "8823\n",
      "8834\n",
      "8835\n",
      "8847\n",
      "8853\n",
      "8855\n",
      "8863\n",
      "8878\n",
      "8909\n",
      "8940\n",
      "8948\n",
      "8964\n",
      "8982\n",
      "8987\n",
      "9013\n",
      "9035\n",
      "9065\n",
      "9075\n",
      "9085\n",
      "9109\n",
      "9114\n",
      "9117\n",
      "9119\n",
      "9132\n",
      "9133\n",
      "9159\n",
      "9160\n",
      "9176\n",
      "9184\n",
      "9194\n",
      "9228\n",
      "9234\n",
      "9260\n",
      "9268\n",
      "9277\n",
      "9289\n",
      "9290\n",
      "9298\n",
      "9315\n",
      "9329\n",
      "9331\n",
      "9337\n",
      "9338\n",
      "9349\n",
      "9360\n",
      "9372\n",
      "9382\n",
      "9391\n",
      "9398\n",
      "9400\n",
      "9422\n",
      "9427\n",
      "9428\n",
      "9465\n",
      "9478\n",
      "9481\n",
      "9482\n",
      "9493\n",
      "9503\n",
      "9513\n",
      "9523\n",
      "9533\n",
      "9545\n",
      "9583\n",
      "9584\n",
      "9588\n",
      "9590\n",
      "9600\n",
      "9606\n",
      "9616\n",
      "9626\n",
      "9651\n",
      "9671\n",
      "9675\n",
      "9685\n",
      "9702\n",
      "9709\n",
      "9719\n",
      "9729\n",
      "9747\n",
      "9749\n",
      "9754\n",
      "9770\n",
      "9777\n",
      "9786\n",
      "9814\n",
      "9830\n",
      "9831\n",
      "9841\n",
      "9853\n",
      "9870\n",
      "9877\n",
      "9883\n",
      "9907\n",
      "9941\n",
      "9970\n",
      "9982\n",
      "9988\n",
      "9998\n"
     ]
    }
   ],
   "source": [
    "for idx, val in enumerate(y_test):\n",
    "    if(val == 5):\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0172571]]\n",
      "true\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADHCAYAAAAJSqg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121935748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showpre(397,395)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
