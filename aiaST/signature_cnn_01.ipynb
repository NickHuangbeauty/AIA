{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten, MaxPooling2D, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n",
    "    for d in range(10):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, 10)\n",
    "            dn = (d + inc) % 10\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    model = Sequential()  \n",
    "    model.add(Conv2D(filters=16,  \n",
    "                 kernel_size=(5,5),  \n",
    "                 padding='same',  \n",
    "                 input_shape=input_shape,  \n",
    "                 activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))  \n",
    "    model.add(Conv2D(filters=36,  \n",
    "                 kernel_size=(5,5),  \n",
    "                 padding='same',  \n",
    "                 input_shape=input_shape,  \n",
    "                 activation='relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "    model.add(Dropout(0.25))  \n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(128, activation='relu'))  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (174, 358, 1)\n",
    "nb_epoch = 10\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_network = create_base_network(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_a = Input(shape=(input_shape))\n",
    "input_b = Input(shape=(input_shape))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model(inputs=[input_a, input_b], outputs=distance)\n",
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread('01/0101.tif',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.resize(im,(358,174),interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x129b8e978>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADFCAYAAABaSzmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVMSGKsopAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126c0f5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 152s - loss: 0.2178 - val_loss: 0.0145\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 149s - loss: 0.0364 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 148s - loss: 0.0077 - val_loss: 0.0198\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0153 - val_loss: 0.0033\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 148s - loss: 0.0049 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 148s - loss: 0.0196 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 148s - loss: 0.0380 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0030 - val_loss: 9.0632e-04\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 147s - loss: 0.0022 - val_loss: 0.0055\n",
      "2\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 147s - loss: 0.1360 - val_loss: 0.0180\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 148s - loss: 0.0101 - val_loss: 0.0124\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 147s - loss: 0.0134 - val_loss: 0.1131\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 150s - loss: 0.0269 - val_loss: 0.0027\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 147s - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 150s - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 151s - loss: 0.0182 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 148s - loss: 0.0109 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0033\n",
      "3\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 149s - loss: 0.0562 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 146s - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 146s - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0011 - val_loss: 0.0023\n",
      "4\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0433 - val_loss: 0.0052\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0094 - val_loss: 9.7493e-04\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0054 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0021 - val_loss: 0.0133\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0025 - val_loss: 0.0031\n",
      "5\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0637 - val_loss: 0.0028\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 135s - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0042 - val_loss: 4.4338e-04\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 152s - loss: 0.0022 - val_loss: 0.0073\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0036 - val_loss: 6.8751e-04\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0012 - val_loss: 9.2083e-04\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 147s - loss: 0.0021 - val_loss: 0.0012\n",
      "6\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 146s - loss: 0.0437 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0041 - val_loss: 0.0077\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0042 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 136s - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0035 - val_loss: 0.0010\n",
      "7\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0665 - val_loss: 0.0029\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 147s - loss: 0.0061 - val_loss: 0.0093\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 147s - loss: 0.0027 - val_loss: 5.6276e-04\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 147s - loss: 0.0031 - val_loss: 0.0010\n",
      "8\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 146s - loss: 0.0220 - val_loss: 0.0025\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0016 - val_loss: 9.8393e-04\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0011 - val_loss: 4.8181e-04\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0018 - val_loss: 8.3267e-04\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 139s - loss: 0.0015 - val_loss: 4.3802e-04\n",
      "9\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 136s - loss: 0.0256 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0014 - val_loss: 9.3554e-04\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0019 - val_loss: 9.7333e-04\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 149s - loss: 0.0013 - val_loss: 4.5413e-04\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0018 - val_loss: 5.9810e-04\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 149s - loss: 0.0012 - val_loss: 7.8682e-04\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 148s - loss: 8.7680e-04 - val_loss: 5.7490e-04\n",
      "10\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 152s - loss: 0.0911 - val_loss: 0.0081\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 148s - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0038 - val_loss: 0.0095\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 146s - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 146s - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0073 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 161s - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 157s - loss: 0.0023 - val_loss: 0.0015\n",
      "11\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 165s - loss: 0.0573 - val_loss: 0.0041\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 157s - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 159s - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 157s - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 152s - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 153s - loss: 0.0041 - val_loss: 0.0167\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 153s - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 159s - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 162s - loss: 0.0033 - val_loss: 6.3542e-04\n",
      "12\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 163s - loss: 0.0792 - val_loss: 0.0075\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 146s - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 161s - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 150s - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0016 - val_loss: 0.0048\n",
      "13\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0448 - val_loss: 0.0052\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 157s - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 149s - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 151s - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 151s - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 147s - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 148s - loss: 0.0045 - val_loss: 5.9422e-04\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 146s - loss: 0.0015 - val_loss: 0.0029\n",
      "14\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0845 - val_loss: 0.0034\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0034 - val_loss: 7.1416e-04\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0024 - val_loss: 9.3910e-04\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0025 - val_loss: 0.0021\n",
      "15\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0790 - val_loss: 0.0062\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0034 - val_loss: 9.2300e-04\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0024 - val_loss: 6.2618e-04\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0019 - val_loss: 0.0099\n",
      "16\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0659 - val_loss: 0.0101\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0025 - val_loss: 9.7802e-04\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0020 - val_loss: 0.0048\n",
      "17\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0190 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0024 - val_loss: 8.9739e-04\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0023 - val_loss: 6.3140e-04\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0019 - val_loss: 0.0018\n",
      "18\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0755 - val_loss: 0.0043\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0024 - val_loss: 6.8499e-04\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0017 - val_loss: 0.0018\n",
      "19\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0598 - val_loss: 0.0039\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0077 - val_loss: 9.3417e-04\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0016 - val_loss: 0.0016\n",
      "20\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0525 - val_loss: 0.0024\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0048 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0027 - val_loss: 0.0068\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0025 - val_loss: 6.4615e-04\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0018 - val_loss: 9.5073e-04\n",
      "21\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0637 - val_loss: 0.0074\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0041 - val_loss: 0.0017\n",
      "22\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0482 - val_loss: 0.0029\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0032 - val_loss: 8.3228e-04\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0022 - val_loss: 0.0016\n",
      "23\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0634 - val_loss: 0.0027\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0070 - val_loss: 7.8589e-04\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0032 - val_loss: 8.1027e-04\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0016 - val_loss: 0.0030\n",
      "24\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0864 - val_loss: 0.0074\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 147s - loss: 0.0062 - val_loss: 0.0026\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 140s - loss: 0.0029 - val_loss: 0.0104\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0072 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0035 - val_loss: 0.0011\n",
      "25\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0435 - val_loss: 0.0046\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0039 - val_loss: 9.0281e-04\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 135s - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0024 - val_loss: 4.3572e-04\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0010 - val_loss: 5.4140e-04\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0012 - val_loss: 3.2657e-04\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 144s - loss: 7.9599e-04 - val_loss: 0.0011\n",
      "26\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 136s - loss: 0.0936 - val_loss: 0.0180\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0069 - val_loss: 0.0019\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 135s - loss: 0.0028 - val_loss: 0.0016\n",
      "27\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.3721 - val_loss: 0.0298\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0113 - val_loss: 0.0039\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0068 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0061 - val_loss: 0.0022\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 146s - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0046 - val_loss: 0.0108\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 147s - loss: 0.0043 - val_loss: 0.0023\n",
      "28\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.1295 - val_loss: 0.0111\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 142s - loss: 0.0107 - val_loss: 0.0039\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0101 - val_loss: 0.0065\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0079 - val_loss: 0.0028\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0055 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0054 - val_loss: 0.0013\n",
      "29\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0947 - val_loss: 0.0138\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0093 - val_loss: 0.0036\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 137s - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0068 - val_loss: 0.0021\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0121 - val_loss: 0.0027\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 138s - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 146s - loss: 0.0041 - val_loss: 8.2493e-04\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0038 - val_loss: 0.0019\n",
      "30\n",
      "(1800, 2, 174, 358, 1)\n",
      "(1800,)\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 143s - loss: 0.0751 - val_loss: 0.0075\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 141s - loss: 0.0070 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 140s - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0058 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 145s - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0039 - val_loss: 9.3325e-04\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 144s - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 139s - loss: 0.0025 - val_loss: 0.0012\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# p for person\n",
    "for p1 in range(1,31):\n",
    "    \n",
    "    tr_pairs = []\n",
    "    tr_y = []\n",
    "    \n",
    "    te_pairs = []\n",
    "    te_y = []\n",
    "    \n",
    "    # l for left\n",
    "    for l in range(1, 31):\n",
    "        for r in range(1, 31):\n",
    "            left = '{:02d}/{:02d}{:02d}.tif'.format(p1, 1, l)\n",
    "            same = '{:02d}/{:02d}{:02d}.tif'.format(p1, 1, r)\n",
    "            diff = '{:02d}/{:02d}{:02d}.tif'.format(r, 3, p1)\n",
    "#             print('{},{}'.format(left, same))\n",
    "#             print('{},{}'.format(left, diff))\n",
    "            \n",
    "            im_left = cv2.imread(left, 0)\n",
    "            im_left = cv2.resize(im_left,(358,174),interpolation=cv2.INTER_CUBIC)\n",
    "            im_left = im_left/255\n",
    "            \n",
    "            im_same = cv2.imread(same, 0)\n",
    "            im_same = cv2.resize(im_same,(358,174),interpolation=cv2.INTER_CUBIC)\n",
    "            im_same = im_same/255\n",
    "            \n",
    "            im_diff = cv2.imread(diff, 0)\n",
    "            im_diff = cv2.resize(im_diff,(358,174),interpolation=cv2.INTER_CUBIC)\n",
    "            im_diff = im_diff/255\n",
    "            \n",
    "            tr_pairs += [im_left, im_same]\n",
    "            tr_y += [1]\n",
    "            \n",
    "            tr_pairs += [im_left, im_diff]\n",
    "            tr_y += [0]\n",
    "            \n",
    "    \n",
    "    tr_pairs = np.array(tr_pairs)\n",
    "    tr_pairs = tr_pairs.reshape(1800, 2, 174, 358, 1)\n",
    "    tr_y = np.array(tr_y)\n",
    "    \n",
    "    print(p1)\n",
    "    print(tr_pairs.shape)\n",
    "    print(tr_y.shape)\n",
    "    \n",
    "    model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], \n",
    "              tr_y,\n",
    "              validation_split=0.2,\n",
    "              batch_size=128,\n",
    "              epochs=nb_epoch)\n",
    "    \n",
    "    file = 'signature_model_{:02d}.h5'.format(p1)\n",
    "    \n",
    "    model.save(file)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('signature_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
