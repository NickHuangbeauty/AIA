{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation, svm, preprocessing, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建Label dict\n",
    "- key是FileID\n",
    "- value是Label\n",
    "- 方便最後塞Label用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(pd.read_csv('training-set.csv',header=None))\n",
    "df_train.columns = ['FileID','Label']\n",
    "\n",
    "dic = df_train.set_index('FileID').to_dict()\n",
    "\n",
    "dic = dic['Label']\n",
    "\n",
    "li = list(df_train['FileID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀檔\n",
    "1. 把之前merge好的大csv讀進來\n",
    "2. Unnamed: 0欄位是沒用的，先刪掉\n",
    "3. 增加一個count欄位，方便算比數（應該有更好的寫法）\n",
    "4. 根據FileID group 幾個欄位出來\n",
    "    - 'Cnum':每個FileID有對應到的不同的CustomerID\n",
    "    - 'Pnum':每個FileID有對應到的不同的ProductID\n",
    "    - 'df_guby_t_max':每個FileID出現的最後時間\n",
    "    - 'df_guby_t_min':每個FileID第一次出現的時間\n",
    "    - 'times':每個FileID出現的次數\n",
    "    - 'time_diff'= df_guby_t_max - df_guby_t_min存在多長的時間，以天為單位\n",
    "    - 'tzone1' :檔案在0~6點被開啟的比例\n",
    "    - 'tzone2' :檔案在7~12點被開啟的比例\n",
    "    - 'tzone3' :檔案在13~18點被開啟的比例\n",
    "    - 'tzone4' :檔案在19~0點被開啟的比例\n",
    "    - 'c_cut' 相關系列的，我把 CustomerID 出現的次數做了簡單的分群，第一群是出現10次以內，第二群是11~100，第三群101~1000，第四群1001~10000，第五群10001~100000，第六群大於100000次。'c_cutr' 相關系列是把 'c_cut'/Cnum變成比例，沒有取代'c_cut'而是新建欄位的用意是，我怕第五第六群萬一是重要的feature又被我稀釋掉的話就沒意義了。\n",
    "    - 'c_cut1' :第一群Customer出現的次數\n",
    "    - 'c_cut2' :第二群Customer出現的次數\n",
    "    - 'c_cut3' :第三群Customer出現的次數\n",
    "    - 'c_cut4' :第四群Customer出現的次數\n",
    "    - 'c_cut5' :第五群Customer出現的次數\n",
    "    - 'c_cut6' :第六群Customer出現的次數\n",
    "    - 'c_cut1r' :第一群Customer出現的比例\n",
    "    - 'c_cut2r' :第二群Customer出現的比例\n",
    "    - 'c_cut3r' :第三群Customer出現的比例\n",
    "    - 'c_cut4r' :第四群Customer出現的比例\n",
    "    - 'c_cut5r' :第五群Customer出現的比例\n",
    "    - 'c_cut6r' :第六群Customer出現的比例\n",
    "    - 'freq' :tim_diff / times file 被點擊的頻率\n",
    "5. 用上面建立好的dict把Label併進來\n",
    "6. 把Label != 3的歸類為X(train data);Label == 3 的歸類為y(test data)\n",
    "7. 用train_test_split把X分成訓練跟驗證資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_log = pd.DataFrame(pd.read_csv('total_log.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_log = df_log.drop(['Unnamed: 0','Label'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_log['count'] = 1\n",
    "\n",
    "df_log['apm'] = pd.to_numeric(df_log['Dtime'].str[11:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cus = df_log.groupby('CustomerID', as_index = False)['count'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cus2 = df_cus[['CustomerID','count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cus2 = pd.DataFrame(df_cus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cus_cut1 = list(df_cus2[df_cus2['count'] <= 10]['CustomerID'])\n",
    "cus_cut2 = list(df_cus2[(df_cus2['count'] > 10) & (df_cus2['count'] <= 100)]['CustomerID'])\n",
    "cus_cut3 = list(df_cus2[(df_cus2['count'] > 100) & (df_cus2['count'] <= 1000)]['CustomerID'])\n",
    "cus_cut4 = list(df_cus2[(df_cus2['count'] > 1000) & (df_cus2['count'] <= 10000)]['CustomerID'])\n",
    "#cus_cut5 = list(df_cus2[(df_cus2['count'] > 10000)]['CustomerID'])\n",
    "cus_cut5 = list(df_cus2[(df_cus2['count'] > 10000) & (df_cus2['count'] <= 100000)]['CustomerID'])\n",
    "cus_cut6 = list(df_cus2[(df_cus2['count'] > 100000)]['CustomerID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1 = list(df_log[df_log['CustomerID'].isin(cus_cut1)].index.values)\n",
    "c2 = list(df_log[df_log['CustomerID'].isin(cus_cut2)].index.values)\n",
    "c3 = list(df_log[df_log['CustomerID'].isin(cus_cut3)].index.values)\n",
    "c4 = list(df_log[df_log['CustomerID'].isin(cus_cut4)].index.values)\n",
    "c5 = list(df_log[df_log['CustomerID'].isin(cus_cut5)].index.values)\n",
    "c6 = list(df_log[df_log['CustomerID'].isin(cus_cut6)].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_log['c_cut1'] = 0\n",
    "df_log['c_cut2'] = 0\n",
    "df_log['c_cut3'] = 0\n",
    "df_log['c_cut4'] = 0 \n",
    "df_log['c_cut5'] = 0 \n",
    "df_log['c_cut6'] = 0 \n",
    "df_log.loc[c1,'c_cut1'] = 1\n",
    "df_log.loc[c2,'c_cut2'] = 1\n",
    "df_log.loc[c3,'c_cut3'] = 1\n",
    "df_log.loc[c4,'c_cut4'] = 1\n",
    "df_log.loc[c5,'c_cut5'] = 1\n",
    "df_log.loc[c6,'c_cut6'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cc = df_log.groupby(['FileID'])['c_cut1','c_cut2','c_cut3','c_cut4','c_cut5','c_cut6'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeZone 處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z1 = list(df_log[(df_log['apm']>0) & (df_log['apm']<=6)].index.values)\n",
    "z2 = list(df_log[(df_log['apm']>6) & (df_log['apm']<=12)].index.values)\n",
    "z3 = list(df_log[(df_log['apm']>12) & (df_log['apm']<=18)].index.values)\n",
    "z4 = list(df_log[(df_log['apm']>18) | (df_log['apm']==0)].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_log['tzone1'] = 0\n",
    "df_log['tzone2'] = 0\n",
    "df_log['tzone3'] = 0\n",
    "df_log['tzone4'] = 0 \n",
    "df_log.loc[z1,'tzone1'] = 1\n",
    "df_log.loc[z2,'tzone2'] = 1\n",
    "df_log.loc[z3,'tzone3'] = 1\n",
    "df_log.loc[z4,'tzone4'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tz = df_log.groupby(['FileID'])['tzone1','tzone2','tzone3','tzone4'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大、最小時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_guby_t_max = df_log.groupby('FileID')['QueryTS'].max()\n",
    "df_guby_t_min = df_log.groupby('FileID')['QueryTS'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_1 = df_log.groupby(['FileID','CustomerID','ProductID'])[['count']].sum()\n",
    "# df_tmin = df_log.groupby(['FileID','CustomerID','ProductID'])[['QueryTS']].first()\n",
    "# df_tmax = df_log.groupby(['FileID','CustomerID','ProductID'])[['QueryTS']].last()\n",
    "# df_mid = df_log.groupby(['FileID','CustomerID','ProductID'])[['QueryTS']].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CustomerID、ProductID unique 數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_guby = df_log.groupby('FileID').CustomerID.nunique()\n",
    "df_gubyp = df_log.groupby('FileID').ProductID.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File 出現的總次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gubycoun = df_log.groupby('FileID')['count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 併 Feature 大表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_data = pd.concat([df_guby, df_gubyp, df_guby_t_max, df_guby_t_min, df_gubycoun, df_tz, df_cc], axis=1)\n",
    "total_data.columns = ['Cnum','Pnum','df_guby_t_max','df_guby_t_min','times','tzone1','tzone2','tzone3','tzone4','c_cut1','c_cut2','c_cut3','c_cut4','c_cut5','c_cut6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算 File 的存在天數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_data['time_diff'] = (total_data['df_guby_t_max'] - total_data['df_guby_t_min'])/(60*60*24)\n",
    "#total_data = total_data.drop(['df_guby_t_max', 'df_guby_t_min'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把 tzone 及 c_cut 轉成比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_data['tzone1'] = (total_data['tzone1'] / total_data['times'])*100\n",
    "total_data['tzone2'] = (total_data['tzone2'] / total_data['times'])*100 \n",
    "total_data['tzone3'] = (total_data['tzone3'] / total_data['times'])*100 \n",
    "total_data['tzone4'] = (total_data['tzone4'] / total_data['times'])*100\n",
    "total_data['c_cut1r'] = (total_data['c_cut1'] / total_data['Cnum'])*100\n",
    "total_data['c_cut2r'] = (total_data['c_cut2'] / total_data['Cnum'])*100\n",
    "total_data['c_cut3r'] = (total_data['c_cut3'] / total_data['Cnum'])*100\n",
    "total_data['c_cut4r'] = (total_data['c_cut4'] / total_data['Cnum'])*100\n",
    "total_data['c_cut5r'] = (total_data['c_cut5'] / total_data['Cnum'])*100\n",
    "total_data['c_cut6r'] = (total_data['c_cut6'] / total_data['Cnum'])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 算 freq \n",
    "- 這邊算頻率的時候我把時間單位換為分，怕天的話有些會太小而被算成0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_data['freq'] = (total_data['time_diff'] * 24 * 60) / total_data['times']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 存Feature大表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 81894 entries, 00008c73ee43c15b16c26b26398c1577 to ffff94db3a63e4fd7585ddc10a2ab044\n",
      "Data columns (total 23 columns):\n",
      "Cnum             81894 non-null int64\n",
      "Pnum             81894 non-null int64\n",
      "df_guby_t_max    81894 non-null int64\n",
      "df_guby_t_min    81894 non-null int64\n",
      "times            81894 non-null int64\n",
      "tzone1           81894 non-null float64\n",
      "tzone2           81894 non-null float64\n",
      "tzone3           81894 non-null float64\n",
      "tzone4           81894 non-null float64\n",
      "c_cut1           81894 non-null int64\n",
      "c_cut2           81894 non-null int64\n",
      "c_cut3           81894 non-null int64\n",
      "c_cut4           81894 non-null int64\n",
      "c_cut5           81894 non-null int64\n",
      "c_cut6           81894 non-null int64\n",
      "time_diff        81894 non-null float64\n",
      "c_cut1r          81894 non-null float64\n",
      "c_cut2r          81894 non-null float64\n",
      "c_cut3r          81894 non-null float64\n",
      "c_cut4r          81894 non-null float64\n",
      "c_cut5r          81894 non-null float64\n",
      "c_cut6r          81894 non-null float64\n",
      "freq             81894 non-null float64\n",
      "dtypes: float64(12), int64(11)\n",
      "memory usage: 15.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# 確定一下沒有null值\n",
    "total_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_data.to_csv('feature_180307.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分離 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df_log[~df_log['FileID'].isin(li)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# total_data['Label'] = 3\n",
    "# for i in range(len(total_data)):\n",
    "#     try:\n",
    "#         total_data['Label'][i] = dic[total_data.index[i]]\n",
    "#     except:\n",
    "#         total_data['Label'][i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_data[train_data['Label'] != 3]\n",
    "y = train_data[train_data['Label'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.drop('Label',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.set_index('FileID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df_train, random_state = 7, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = train_data.values #returns a numpy array\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(x)\n",
    "# df = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM\n",
    "- 裝XGB的時候碰到了問題，所以先用GBM做了\n",
    "- 做出來的預測是0,1不是機率（有點大的問題）\n",
    "- train的時候沒有做很多的校調，一次就傳上去了（結果只有0.5哈哈哈哈（別打我"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=500,max_depth=10,min_samples_split=5,min_samples_leaf=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=10,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=3, min_samples_split=5,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_y = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.99%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, pred_y )\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y.drop('Label',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y['Probability'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_final = y.drop(['Cnum','Pnum','times','time_diff'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_final['FileID'] = y_final.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_y = y_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_y = df_y[['FileID', 'Probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_y.to_csv('tbrain_v2.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
